{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d61b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', None, 'max_colwidth', 250)\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091c382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams more than east teams right?</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york nigga\" ones are.</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                     comment  \\\n",
       "0                                                                                                                 NC and NH.   \n",
       "1                                                 You do know west teams play against west teams more than east teams right?   \n",
       "2  They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1   \n",
       "3                                                               This meme isn't funny none of the \"new york nigga\" ones are.   \n",
       "4                                                                                            I could use one of those tools.   \n",
       "\n",
       "                                                                                                                           parent_comment  \n",
       "0                                                        Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.  \n",
       "2                                                                                                                 They're favored to win.  \n",
       "3                                                                                                              deadass don't kill my buzz  \n",
       "4                                                   Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = pd.read_csv('comment_plus_parent.csv', index_col=0)\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7e8ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010714, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4f4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reddit.pop('label')\n",
    "X = reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18890b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010714, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c261144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010714,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d025c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split into test and remainder\n",
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07815340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second split into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_remainder, y_remainder, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2a1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    \n",
    "    num_range = range(0,10**3)\n",
    "    \n",
    "    for num in num_range:\n",
    "        sentence = sentence.replace(str(num), '')\n",
    "    \n",
    "    # remove punctuation and set to lower case\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "        \n",
    "    \n",
    "    # split sentence into words\n",
    "    words_list = sentence.split(' ')\n",
    "    stemmed_words = []\n",
    "    \n",
    "    \n",
    "    # remove stopwords and any tokens that are just empty strings\n",
    "    for word in words_list:\n",
    "        if (not word in stop_words) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            stemmed_words.append(stemmed_word)\n",
    "\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4afef237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gravi\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiating transformers to pass into column transformer\n",
    "transformers = [('comment', CountVectorizer(min_df=25, tokenizer=tokenizer, max_features=750, dtype=np.int8), 'comment'),\n",
    "                 ('parent', CountVectorizer(min_df=25, tokenizer=tokenizer, max_features=750, dtype=np.int8), 'parent_comment')]\n",
    "                \n",
    "\n",
    "# Creating the column transformer\n",
    "column_transform = ColumnTransformer(transformers)\n",
    "\n",
    "# Fitting and transforming train, test, val\n",
    "X_train_tokens = column_transform.fit_transform(X_train)\n",
    "X_val_tokens = column_transform.transform(X_val)\n",
    "X_test_tokens = column_transform.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c0385",
   "metadata": {},
   "source": [
    "Potential random sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbdb5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568526, 1500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors = pd.DataFrame(columns=column_transform.get_feature_names_out(), data=X_train_tokens.toarray())\n",
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cceb5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189509, 1500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vectors = pd.DataFrame(columns=column_transform.get_feature_names_out(), data=X_val_tokens.toarray())\n",
    "val_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a7f551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252679, 1500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors = pd.DataFrame(columns=column_transform.get_feature_names_out(), data=X_test_tokens.toarray())\n",
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f13572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.6529270429144841\n",
      "Val score: 0.6496841838646186\n",
      "Val score: 0.6502756461755824\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=5000, random_state=42)\n",
    "\n",
    "logreg.fit(train_vectors, y_train)\n",
    "\n",
    "print(f'Train score: {logreg.score(train_vectors, y_train)}')\n",
    "print(f'Val score: {logreg.score(val_vectors, y_val)}')\n",
    "print(f'Val score: {logreg.score(test_vectors, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc63e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
